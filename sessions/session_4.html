

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Sesión 4 — Preprocesamiento y transformación de datos &mdash; SIQ025 — Programari Professional d&#39;Anàlisi de Dades  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Sesión 3 — Limpieza de datos" href="session_3.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            SIQ025 — Programari Professional d'Anàlisi de Dades
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Sesiones</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="session_1.html">Sesión 1 — Introducción al Análisis de Datos con Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="session_2.html">Sesión 2 — Importación y manipulación de datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="session_3.html">Sesión 3 — Limpieza de datos</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Sesión 4 — Preprocesamiento y transformación de datos</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#objetivos">Objetivos</a></li>
<li class="toctree-l2"><a class="reference internal" href="#introduccion">Introducción</a></li>
<li class="toctree-l2"><a class="reference internal" href="#escalado-y-normalizacion-de-variables-numericas">Escalado y normalización de variables numéricas</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cuando-usar-cada-tipo-de-escalado">¿Cuándo usar cada tipo de escalado?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#codificacion-de-variables-categoricas">Codificación de variables categóricas</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#one-hot-encoding">One-Hot Encoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#label-ordinal-encoding">Label / Ordinal Encoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#target-encoding-codificacion-por-el-objetivo">Target Encoding (codificación por el objetivo)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#feature-engineering-basico">Feature engineering básico</a></li>
<li class="toctree-l2"><a class="reference internal" href="#imputacion-de-valores-faltantes-en-scikit-learn">Imputación de valores faltantes en scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pipelines-de-preprocesamiento-con-scikit-learn">Pipelines de preprocesamiento con scikit-learn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#que-esta-pasando-aqui">¿Qué está pasando aquí?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#integracion-de-limpieza-y-transformacion-en-un-flujo-reproducible">Integración de limpieza y transformación en un flujo reproducible</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ejercicios-sugeridos">Ejercicios sugeridos</a></li>
<li class="toctree-l2"><a class="reference internal" href="#conclusiones-de-la-sesion">Conclusiones de la sesión</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SIQ025 — Programari Professional d'Anàlisi de Dades</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Sesión 4 — Preprocesamiento y transformación de datos</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/sessions/session_4.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sesion-4-preprocesamiento-y-transformacion-de-datos">
<h1>Sesión 4 — Preprocesamiento y transformación de datos<a class="headerlink" href="#sesion-4-preprocesamiento-y-transformacion-de-datos" title="Link to this heading"></a></h1>
<section id="objetivos">
<h2>Objetivos<a class="headerlink" href="#objetivos" title="Link to this heading"></a></h2>
<p>En esta sesión aprenderemos a <strong>preparar datos para modelado</strong> aplicando transformaciones estándar y a construir pipelines reproducibles.</p>
<p>Al finalizar la sesión, serás capaz de:</p>
<ul class="simple">
<li><p>Aplicar <strong>escalado</strong> y <strong>normalización</strong> a variables numéricas.</p></li>
<li><p>Codificar variables categóricas mediante <strong>One-Hot</strong>, <strong>Label Encoding</strong> y estrategias como <strong>Target Encoding</strong>.</p></li>
<li><p>Realizar <strong>feature engineering</strong> básico para crear variables derivadas.</p></li>
<li><p>Construir pipelines de preprocesamiento con scikit-learn y combinar limpieza y transformación en un flujo reproducible.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="introduccion">
<h2>Introducción<a class="headerlink" href="#introduccion" title="Link to this heading"></a></h2>
<p>En las sesiones anteriores hemos visto cómo <strong>cargar</strong> y <strong>limpiar</strong> datos. El siguiente paso antes de entrenar modelos es <strong>transformar</strong> esos datos a una forma que los algoritmos puedan aprovechar bien.</p>
<p>A este conjunto de pasos lo llamamos <strong>preprocesamiento</strong>. Incluye, entre otros:</p>
<ul class="simple">
<li><p>Ajustar la <strong>escala</strong> de las variables numéricas.</p></li>
<li><p>Convertir variables categóricas (texto) a <strong>números</strong>.</p></li>
<li><p>Crear nuevas variables que resuman o combinen información (<strong>feature engineering</strong>).</p></li>
<li><p>Integrar todo en un flujo reproducible (<strong>pipelines</strong>) que podamos aplicar tanto en entrenamiento como en producción.</p></li>
</ul>
<p>La idea clave:</p>
<blockquote>
<div><p>El mismo conjunto de pasos que aplicamos sobre los datos de entrenamiento debe poder aplicarse después, exactamente igual, a nuevos datos (por ejemplo, datos de test o datos en producción).</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="escalado-y-normalizacion-de-variables-numericas">
<h2>Escalado y normalización de variables numéricas<a class="headerlink" href="#escalado-y-normalizacion-de-variables-numericas" title="Link to this heading"></a></h2>
<p>Muchos modelos de machine learning <strong>suponen</strong> o <strong>agradecen</strong> que las variables numéricas tengan una escala comparable.<br />
Ejemplos:</p>
<ul class="simple">
<li><p>KNN (distancias): si una variable está medida en miles y otra entre 0 y 1, la primera dominará la distancia.</p></li>
<li><p>Regresión lineal / logística con regularización: la penalización se ve afectada por la escala.</p></li>
<li><p>SVM, PCA, redes neuronales… también suelen mejorar cuando las variables están escaladas.</p></li>
</ul>
<p>En pandas y scikit-learn el escalado se hace con transformadores como <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> o <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span>

<span class="c1"># df: DataFrame con columnas numéricas</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;edad&#39;</span><span class="p">,</span> <span class="s1">&#39;ingresos&#39;</span><span class="p">,</span> <span class="s1">&#39;area&#39;</span><span class="p">]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">])</span>

<span class="c1"># Alternativa: Min-Max</span>
<span class="n">mms</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">mms</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">])</span>
</pre></div>
</div>
<section id="cuando-usar-cada-tipo-de-escalado">
<h3>¿Cuándo usar cada tipo de escalado?<a class="headerlink" href="#cuando-usar-cada-tipo-de-escalado" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>StandardScaler</strong></p>
<ul>
<li><p>Qué hace: resta la media y divide por la desviación estándar → cada columna queda con media ≈ 0 y desviación ≈ 1.</p></li>
<li><p>Cuándo usarlo:</p>
<ul>
<li><p>Cuando las variables tienen una distribución más o menos <strong>gaussiana</strong>.</p></li>
<li><p>Cuando usamos modelos como <strong>regresión lineal/logística</strong>, <strong>SVM</strong>, <strong>KNN</strong>, <strong>PCA</strong>.</p></li>
</ul>
</li>
<li><p>Ventaja: mantiene la forma de la distribución (solo cambia centro y escala).</p></li>
</ul>
</li>
<li><p><strong>MinMaxScaler</strong></p>
<ul>
<li><p>Qué hace: transforma cada columna para que sus valores estén en un rango dado (por defecto [0, 1]).</p></li>
<li><p>Cuándo usarlo:</p>
<ul>
<li><p>Cuando queremos mantener <strong>proporciones</strong> y trabajar en un rango acotado (por ejemplo, redes neuronales sencillas).</p></li>
<li><p>Cuando sabemos que los datos no tienen outliers muy extremos.</p></li>
</ul>
</li>
<li><p>Inconveniente: es <strong>sensible a outliers</strong> (un valor extremo estira todo el rango).</p></li>
</ul>
</li>
<li><p><strong>Normalizer</strong> (normalización por norma)</p>
<ul>
<li><p>Qué hace: escala <strong>cada fila</strong> (cada muestra) para que su vector tenga norma 1 (por ejemplo, norma L2).</p></li>
<li><p>Cuándo usarlo:</p>
<ul>
<li><p>Cuando nos importa más la <strong>dirección</strong> del vector que su magnitud.</p></li>
<li><p>Típico en problemas de texto con <strong>TF-IDF</strong>, donde se compara la similitud de documentos.</p></li>
</ul>
</li>
<li><p>Importante: no es lo mismo que escalar columnas; aquí se normaliza por <strong>filas</strong>.</p></li>
</ul>
</li>
<li><p><strong>RobustScaler</strong></p>
<ul>
<li><p>Qué hace: usa mediana e IQR (rango intercuartílico) para escalar, por lo que es <strong>robusto a outliers</strong>.</p></li>
<li><p>Cuándo usarlo:</p>
<ul>
<li><p>Cuando hay valores atípicos (muy grandes o muy pequeños) que podrían distorsionar StandardScaler o MinMaxScaler.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Cuándo NO hace falta escalar</strong></p>
<ul>
<li><p>Modelos basados en árboles (DecisionTree, RandomForest, GradientBoosting, XGBoost…) <strong>no requieren</strong> escalado para funcionar bien:</p>
<ul>
<li><p>Dividen el espacio según umbrales, no por distancias.</p></li>
<li><p>Escalar o no suele cambiar poco o nada en su rendimiento.</p></li>
</ul>
</li>
<li><p>Aun así, en pipelines mixtos (con otras técnicas) puede ser útil mantener un tratamiento homogéneo.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="codificacion-de-variables-categoricas">
<h2>Codificación de variables categóricas<a class="headerlink" href="#codificacion-de-variables-categoricas" title="Link to this heading"></a></h2>
<p>Los modelos de scikit-learn trabajan, en general, con <strong>números</strong>, no con texto.<br />
Por tanto, las variables categóricas (por ejemplo, <code class="docutils literal notranslate"><span class="pre">ciudad</span> <span class="pre">=</span> <span class="pre">&quot;Madrid&quot;</span></code>) deben convertirse a representaciones numéricas.</p>
<p>Hay varias estrategias, con ventajas e inconvenientes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">OrdinalEncoder</span>

<span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ciudad&#39;</span><span class="p">,</span> <span class="s1">&#39;tipo_vivienda&#39;</span><span class="p">]</span>

<span class="c1"># One-Hot (útil para muchos modelos, especialmente lineales)</span>
<span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">ohe_arr</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">cat_cols</span><span class="p">])</span>

<span class="c1"># Label / Ordinal encoding (si el orden tiene sentido o para tree models)</span>
<span class="n">ord_enc</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;tipo_vivienda_ord&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ord_enc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;tipo_vivienda&#39;</span><span class="p">]])</span>
</pre></div>
</div>
<section id="one-hot-encoding">
<h3>One-Hot Encoding<a class="headerlink" href="#one-hot-encoding" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Crea una columna binaria (0/1) por cada categoría.</p></li>
<li><p>Ejemplo: <code class="docutils literal notranslate"><span class="pre">color</span> <span class="pre">=</span> <span class="pre">[&quot;rojo&quot;,</span> <span class="pre">&quot;azul&quot;,</span> <span class="pre">&quot;verde&quot;]</span></code> → columnas <code class="docutils literal notranslate"><span class="pre">color_rojo</span></code>, <code class="docutils literal notranslate"><span class="pre">color_azul</span></code>, <code class="docutils literal notranslate"><span class="pre">color_verde</span></code>.</p></li>
<li><p>Ventajas:</p>
<ul>
<li><p>No introduce un <strong>orden artificial</strong> entre categorías.</p></li>
<li><p>Bien entendido por <strong>modelos lineales</strong>, redes neuronales, etc.</p></li>
</ul>
</li>
<li><p>Inconvenientes:</p>
<ul>
<li><p>Si hay muchas categorías, se generan muchas columnas (problema de <strong>dimensionalidad</strong>).</p></li>
</ul>
</li>
<li><p>Parámetros clave:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">handle_unknown='ignore'</span></code> evita errores cuando aparece una categoría nueva en predicción.</p></li>
</ul>
</li>
</ul>
</section>
<section id="label-ordinal-encoding">
<h3>Label / Ordinal Encoding<a class="headerlink" href="#label-ordinal-encoding" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Asigna un número entero a cada categoría: <code class="docutils literal notranslate"><span class="pre">&quot;piso&quot;</span> <span class="pre">→</span> <span class="pre">0</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;casa&quot;</span> <span class="pre">→</span> <span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;ático&quot;</span> <span class="pre">→</span> <span class="pre">2</span></code>, etc.</p></li>
<li><p>Ventajas:</p>
<ul>
<li><p>Muy sencillo y compacto (una sola columna).</p></li>
</ul>
</li>
<li><p>Inconvenientes:</p>
<ul>
<li><p>Introduce un <strong>orden artificial</strong> entre categorías que puede no existir (¿es “ático” &gt; “piso”?).</p></li>
<li><p>Para modelos lineales, esto puede llevar a interpretaciones erróneas.</p></li>
</ul>
</li>
</ul>
<p>Se usa con más sentido cuando:</p>
<ul class="simple">
<li><p>La variable tiene un orden natural (por ejemplo: <code class="docutils literal notranslate"><span class="pre">[&quot;bajo&quot;,</span> <span class="pre">&quot;medio&quot;,</span> <span class="pre">&quot;alto&quot;]</span></code>).</p></li>
<li><p>O cuando usamos <strong>modelos de árboles</strong>, que no interpretan el número como distancia, sino solo para comparar.</p></li>
</ul>
</section>
<section id="target-encoding-codificacion-por-el-objetivo">
<h3>Target Encoding (codificación por el objetivo)<a class="headerlink" href="#target-encoding-codificacion-por-el-objetivo" title="Link to this heading"></a></h3>
<p>En problemas supervisados (tenemos una variable objetivo <code class="docutils literal notranslate"><span class="pre">y</span></code>, por ejemplo el precio o si algo es fraude), podemos codificar categorías usando información del objetivo.</p>
<p>Ejemplo simple con pandas:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Encoding por media del objetivo por categoría (simple y con smoothing en práctica)</span>
<span class="n">target_mean</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;ciudad&#39;</span><span class="p">)[</span><span class="s1">&#39;precio&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;ciudad_te&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;ciudad&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">target_mean</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Idea: cada categoría se sustituye por la <strong>media del objetivo</strong> para esa categoría.</p>
<ul>
<li><p>Ejemplo: si en “Madrid” el precio medio es 300k y en “Sevilla” es 200k, entonces:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">ciudad_te</span> <span class="pre">=</span> <span class="pre">300000</span></code> para registros de Madrid,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ciudad_te</span> <span class="pre">=</span> <span class="pre">200000</span></code> para registros de Sevilla.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Ventajas:</p>
<ul>
<li><p>Muy potente cuando hay <strong>muchas categorías</strong> y algunas tienen pocos datos.</p></li>
</ul>
</li>
<li><p>Riesgo importante:</p>
<ul>
<li><p><strong>Fuga de información (data leakage)</strong> si calculas las medias usando <strong>todo</strong> el dataset (incluyendo test).</p></li>
<li><p>Para evitarlo, debe calcularse <strong>solo con datos de entrenamiento</strong> y, mejor todavía, con esquemas tipo K-fold.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="feature-engineering-basico">
<h2>Feature engineering básico<a class="headerlink" href="#feature-engineering-basico" title="Link to this heading"></a></h2>
<p><strong>Feature engineering</strong> es el proceso de crear nuevas variables (features) a partir de las existentes para dar más información útil al modelo.</p>
<p>La idea es:</p>
<blockquote>
<div><p>A veces, una combinación adecuada de columnas explica mucho mejor el problema que las columnas originales por separado.</p>
</div></blockquote>
<p>Ejemplos:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplos</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;area_m2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;largo&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;ancho&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;precio_por_m2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;precio&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;area_m2&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;anio_antiguedad&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2025</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;anio_construccion&#39;</span><span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">area_m2</span></code>: a partir de <code class="docutils literal notranslate"><span class="pre">largo</span></code> y <code class="docutils literal notranslate"><span class="pre">ancho</span></code>.</p>
<ul>
<li><p>Útil en problemas de viviendas, terrenos, etc.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">precio_por_m2</span></code>: normaliza el precio respecto al tamaño.</p>
<ul>
<li><p>Permite comparar viviendas de distinto tamaño de forma más justa.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">anio_antiguedad</span></code>: transforma un año en una medida de “cuántos años tiene”.</p>
<ul>
<li><p>Más interpretable para el modelo que el año en bruto.</p></li>
</ul>
</li>
</ul>
<p>Buenas prácticas:</p>
<ul class="simple">
<li><p>Crear features que tengan <strong>sentido de negocio</strong> (no combinaciones aleatorias).</p></li>
<li><p>Evaluar su utilidad:</p>
<ul>
<li><p>Mirando correlaciones.</p></li>
<li><p>Probando modelos con y sin ellas y comparando métricas.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="imputacion-de-valores-faltantes-en-scikit-learn">
<h2>Imputación de valores faltantes en scikit-learn<a class="headerlink" href="#imputacion-de-valores-faltantes-en-scikit-learn" title="Link to this heading"></a></h2>
<p>En la <strong>sesión 3</strong> ya vimos cómo detectar y tratar valores faltantes utilizando <strong>pandas</strong>, por ejemplo con métodos como <code class="docutils literal notranslate"><span class="pre">.isna()</span></code>, <code class="docutils literal notranslate"><span class="pre">.fillna()</span></code> o <code class="docutils literal notranslate"><span class="pre">dropna()</span></code>.<br />
Esa aproximación es muy útil para una primera limpieza manual y exploratoria de los datos.</p>
<p>En esta sesión damos un paso más: veremos cómo realizar la <strong>imputación de valores faltantes dentro de los pipelines de scikit-learn</strong>, de forma que el proceso quede integrado y sea completamente <strong>reproducible</strong>. La idea es que:</p>
<ul class="simple">
<li><p>El cálculo de los valores de imputación (media, mediana, moda, etc.) se haga <strong>solo con los datos de entrenamiento</strong>.</p></li>
<li><p>Esos mismos parámetros se apliquen automáticamente a cualquier dato nuevo (validación, test, producción).</p></li>
</ul>
<p>Para esto utilizamos el transformador <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.impute</span><span class="w"> </span><span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/ejemplo.csv&quot;</span><span class="p">)</span>

<span class="c1"># Columnas numéricas</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;edad&quot;</span><span class="p">,</span> <span class="s2">&quot;ingresos&quot;</span><span class="p">]</span>

<span class="n">imputer_num</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">imputer_num</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">num_cols</span><span class="p">])</span>

<span class="c1"># Columnas categóricas (ejemplo)</span>
<span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ciudad&quot;</span><span class="p">]</span>
<span class="n">imputer_cat</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;most_frequent&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="n">cat_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">imputer_cat</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">cat_cols</span><span class="p">])</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Para <strong>numéricas</strong>, suele ser habitual usar:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">strategy=&quot;mean&quot;</span></code> (media) o</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">strategy=&quot;median&quot;</span></code> (mediana, más robusta a outliers).</p></li>
</ul>
</li>
<li><p>Para <strong>categóricas</strong>, una opción sencilla es:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">strategy=&quot;most_frequent&quot;</span></code> (valor más frecuente).</p></li>
</ul>
</li>
</ul>
<p>Más adelante, integraremos estos <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> dentro de un <strong><code class="docutils literal notranslate"><span class="pre">Pipeline</span></code></strong> y de un <strong><code class="docutils literal notranslate"><span class="pre">ColumnTransformer</span></code></strong>, de forma que la imputación se aplique junto con el resto de transformaciones (escalado, codificación, etc.).</p>
</section>
<hr class="docutils" />
<section id="pipelines-de-preprocesamiento-con-scikit-learn">
<h2>Pipelines de preprocesamiento con scikit-learn<a class="headerlink" href="#pipelines-de-preprocesamiento-con-scikit-learn" title="Link to this heading"></a></h2>
<p>Hasta ahora hemos visto transformaciones por separado. En proyectos reales, queremos:</p>
<ol class="arabic simple">
<li><p>Definir <strong>todas las transformaciones</strong> (imputación, escalado, codificación, etc.).</p></li>
<li><p>Aplicarlas siempre en el <strong>mismo orden</strong>.</p></li>
<li><p>Integrarlas con el <strong>modelo</strong> para que todo se entrene junto.</p></li>
</ol>
<p>Para esto usamos dos componentes clave de scikit-learn:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ColumnTransformer</span></code>: permite aplicar <strong>transformaciones distintas a grupos de columnas diferentes</strong> (numéricas vs categóricas).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>: encadena varios pasos secuenciales (preprocesamiento + modelo).</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.compose</span><span class="w"> </span><span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.impute</span><span class="w"> </span><span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span>

<span class="n">num_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;edad&#39;</span><span class="p">,</span> <span class="s1">&#39;ingresos&#39;</span><span class="p">,</span> <span class="s1">&#39;area&#39;</span><span class="p">]</span>
<span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ciudad&#39;</span><span class="p">,</span> <span class="s1">&#39;tipo_vivienda&#39;</span><span class="p">]</span>

<span class="n">num_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">cat_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">num_pipe</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">cat_pipe</span><span class="p">,</span> <span class="n">cat_cols</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;preproc&#39;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Entrenar pipeline completo</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;precio&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;precio&#39;</span><span class="p">]</span>
<span class="n">model_pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<section id="que-esta-pasando-aqui">
<h3>¿Qué está pasando aquí?<a class="headerlink" href="#que-esta-pasando-aqui" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">num_pipe</span></code></strong>:</p>
<ul class="simple">
<li><p>Primero imputa valores faltantes numéricos con la <strong>mediana</strong>.</p></li>
<li><p>Luego aplica <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> para escalar esas columnas.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">cat_pipe</span></code></strong>:</p>
<ul class="simple">
<li><p>Imputa valores faltantes categóricos con el <strong>valor más frecuente</strong>.</p></li>
<li><p>Aplica <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code> para pasar texto a variables binarias.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">preprocessor</span></code> (ColumnTransformer)</strong>:</p>
<ul class="simple">
<li><p>Aplica <code class="docutils literal notranslate"><span class="pre">num_pipe</span></code> solo a <code class="docutils literal notranslate"><span class="pre">num_cols</span></code>.</p></li>
<li><p>Aplica <code class="docutils literal notranslate"><span class="pre">cat_pipe</span></code> solo a <code class="docutils literal notranslate"><span class="pre">cat_cols</span></code>.</p></li>
<li><p>Devuelve una matriz combinada con todas las nuevas columnas.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">model_pipe</span></code> (Pipeline)</strong>:</p>
<ul class="simple">
<li><p>Paso 1: <code class="docutils literal notranslate"><span class="pre">preproc</span></code> → aplica todo el preprocesamiento anterior.</p></li>
<li><p>Paso 2: <code class="docutils literal notranslate"><span class="pre">model</span></code> → entrena un <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor</span></code> con los datos ya preprocesados.</p></li>
</ul>
</li>
</ol>
<p>Ventajas de este enfoque:</p>
<ul class="simple">
<li><p><strong>Reproducibilidad</strong>: entrenar y predecir usan exactamente los mismos pasos.</p></li>
<li><p><strong>Evita fugas de información</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code> de los transformadores se hace solo con los datos de entrenamiento dentro del pipeline.</p></li>
</ul>
</li>
<li><p><strong>Simplicidad</strong>:</p>
<ul>
<li><p>Para predecir nuevas muestras solo llamamos a <code class="docutils literal notranslate"><span class="pre">model_pipe.predict(nuevos_datos)</span></code>.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="integracion-de-limpieza-y-transformacion-en-un-flujo-reproducible">
<h2>Integración de limpieza y transformación en un flujo reproducible<a class="headerlink" href="#integracion-de-limpieza-y-transformacion-en-un-flujo-reproducible" title="Link to this heading"></a></h2>
<p>En un proyecto real, el flujo típico sería:</p>
<ol class="arabic simple">
<li><p>Cargar datos brutos.</p></li>
<li><p>Aplicar <strong>limpieza básica</strong> (por ejemplo, corrección de tipos, eliminación de registros imposibles).</p></li>
<li><p>Definir un <strong>pipeline de preprocesamiento</strong>:</p>
<ul class="simple">
<li><p>Imputación de nulos.</p></li>
<li><p>Escalado numérico.</p></li>
<li><p>Codificación categórica.</p></li>
<li><p>(Opcional) creación de nuevas features.</p></li>
</ul>
</li>
<li><p>Integrar ese pipeline con uno o varios <strong>modelos</strong>.</p></li>
<li><p>Guardar el pipeline entrenado para reutilizarlo (por ejemplo, con <code class="docutils literal notranslate"><span class="pre">joblib</span></code>).</p></li>
</ol>
<p>Buenas prácticas:</p>
<ul class="simple">
<li><p>Separar claramente:</p>
<ul>
<li><p>Limpieza “física” de datos (formato, columnas imposibles) → puede hacerse antes del pipeline.</p></li>
<li><p>Transformaciones estadísticas (imputación, escalado, codificación) → mejor dentro del pipeline.</p></li>
</ul>
</li>
<li><p>Ajustar (<code class="docutils literal notranslate"><span class="pre">fit</span></code>) los transformadores siempre solo con <strong>entrenamiento</strong>, no con test.</p></li>
<li><p>Documentar las decisiones: por qué elegimos una estrategia de imputación, por qué este scaler, etc.</p></li>
<li><p>Versionar datos, código y modelos (por ejemplo, en Git).</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="ejercicios-sugeridos">
<h2>Ejercicios sugeridos<a class="headerlink" href="#ejercicios-sugeridos" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Transformar un dataset completo aplicando:</p>
<ul class="simple">
<li><p>Imputación de valores faltantes en variables numéricas y categóricas.</p></li>
<li><p>Escalado de las variables numéricas.</p></li>
<li><p>Codificación de las variables categóricas.</p></li>
</ul>
</li>
<li><p>Crear un <strong>pipeline de preprocesamiento</strong> que integre escalado y codificación y conectarlo con un modelo (por ejemplo, regresión lineal o RandomForest).</p></li>
<li><p>Comparar el rendimiento del mismo modelo:</p>
<ul class="simple">
<li><p>Sin preprocesamiento (solo variables crudas).</p></li>
<li><p>Con preprocesamiento completo (pipeline).</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="conclusiones-de-la-sesion">
<h2>Conclusiones de la sesión<a class="headerlink" href="#conclusiones-de-la-sesion" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>El <strong>preprocesamiento</strong> es una parte esencial del flujo de machine learning: condiciona fuertemente la calidad de los modelos.</p></li>
<li><p>Escalar y codificar adecuadamente las variables permite que los algoritmos trabajen de forma más <strong>estable y eficiente</strong>.</p></li>
<li><p>El <strong>feature engineering</strong> puede aportar mucha información extra al modelo y mejorar su rendimiento.</p></li>
<li><p>Los <strong>pipelines</strong> y <code class="docutils literal notranslate"><span class="pre">ColumnTransformer</span></code> son herramientas clave para crear flujos de trabajo <strong>reproducibles</strong>, evitar errores y facilitar el despliegue del modelo.</p></li>
<li><p>A partir de esta sesión podremos construir modelos más robustos y profesionales en las siguientes etapas del curso.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="session_3.html" class="btn btn-neutral float-left" title="Sesión 3 — Limpieza de datos" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>